# ğŸŒ Multi-Language Sentiment Analysis System

A Python-based sentiment analysis system that supports Korean, Chinese, English, and Japanese text analysis.

## ğŸŒŸ Key Features

- **ğŸŒ Multi-language Support**: Automatic detection and analysis of Korean, Chinese, English, and Japanese text
- **ğŸ“Š Excel I/O**: Excel file reading/writing with visualization output
- **ğŸ¤– Advanced Models**: State-of-the-art pre-trained models for each language
- **ğŸ¨ Visualization**: Charts, wordclouds, and comparison graphs
- **âš¡ Batch Processing**: Efficient processing of multiple sheets and large datasets
- **ğŸ”§ Flexible Configuration**: Language-specific model selection and processing parameter customization

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Run Analysis
```bash
cd src

# Option 1: Analyze Excel file (place in output/ folder first)
python main.py your_data.xlsx

# Option 2: Create sample data and run analysis
python main.py

# Option 3: Force create sample data
python main.py --sample

# Option 4: Show help
python main.py --help
```

## ğŸ“ Project Structure

```
p-sentiment-analysis-multi-language/
â”œâ”€â”€ ğŸ“ src/                          # Source code
â”‚   â”œâ”€â”€ ğŸš€ main.py                   # Main execution file (with sample data creation)
â”‚   â”œâ”€â”€ âš™ï¸ core_config.py            # Configuration management
â”‚   â”œâ”€â”€ ğŸ¤– core_models.py            # Model management
â”‚   â”œâ”€â”€ ğŸŒ core_language.py          # Language detection
â”‚   â”œâ”€â”€ ğŸ“Š data_excel.py             # Excel data processing
â”‚   â”œâ”€â”€ ğŸ¨ data_charts.py            # Visualization
â”‚   â”œâ”€â”€ ğŸ“ data_sample.py            # Sample data creation
â”‚   â””â”€â”€ ğŸ“ colab/                    # Google Colab notebooks
â”‚       â”œâ”€â”€ ğŸ‡°ğŸ‡· korean_sentiment_analysis.ipynb
â”‚       â”œâ”€â”€ ğŸ‡¨ğŸ‡³ chinese_sentiment_analysis.ipynb
â”‚       â”œâ”€â”€ ğŸ‡ºğŸ‡¸ english_sentiment_analysis.ipynb
â”‚       â”œâ”€â”€ ğŸ‡¯ğŸ‡µ japanese_sentiment_analysis.ipynb
â”‚       â””â”€â”€ ğŸ”§ create_notebooks.py   # Notebook generation script
â”œâ”€â”€ ğŸ“ output/                       # Results and system files
â”‚   â”œâ”€â”€ ğŸ‡°ğŸ‡· korea/                   # Korean results
â”‚   â”œâ”€â”€ ğŸ‡¨ğŸ‡³ china/                   # Chinese results
â”‚   â”œâ”€â”€ ğŸ‡ºğŸ‡¸ english/                 # English results
â”‚   â”œâ”€â”€ ğŸ‡¯ğŸ‡µ japan/                   # Japanese results
â”‚   â”œâ”€â”€ ğŸ“Š Language_Comparison_Chart.png
â”‚   â””â”€â”€ ğŸ“ logs/                     # System logs
â””â”€â”€ ğŸ“‹ requirements.txt               # Dependency packages
```

## ğŸ¯ Supported Languages

| Language | Code | Primary Model | Alternative Model | Fallback Model |
|----------|------|---------------|-------------------|----------------|
| ğŸ‡°ğŸ‡· Korean | `k` | snunlp/KR-FinBert-SC | beomi/KcELECTRA-base-v2022 | klue/roberta-base |
| ğŸ‡¨ğŸ‡³ Chinese | `c` | IDEA-CCNL/Erlangshen-RoBERTa-110M-Sentiment | IDEAL-Future/bert-base-chinese-finetuned-douban-movie | hfl/chinese-roberta-wwm-ext |
| ğŸ‡ºğŸ‡¸ English | `e` | cardiffnlp/twitter-roberta-base-sentiment-latest | nlptown/bert-base-multilingual-uncased-sentiment | distilbert-base-uncased-finetuned-sst-2-english |
| ğŸ‡¯ğŸ‡µ Japanese | `j` | cl-tohoku/bert-base-japanese-v3 | rinna/japanese-roberta-base | megagonlabs/roberta-base-japanese-sentiment |

## ğŸ“Š Output Results

### ğŸ“ File Results
- **Excel Files**: Sentiment labels, confidence scores, and metadata
- **Charts**: Bar charts, pie charts, and confidence histograms
- **WordClouds**: Text frequency visualizations
- **Comparison Charts**: Cross-language sentiment analysis comparison

### ğŸ¨ Visualization Examples
- Sentiment distribution bar charts
- Confidence distribution by sentiment
- Sentiment distribution pie charts
- Keyword wordclouds
- Cross-language sentiment comparison charts

## ğŸ”§ Configuration and Customization

### Core Configuration File
You can customize the following items in `src/core_config.py`:

- **Model Selection**: Language-specific model selection
- **Processing Parameters**: Batch size, maximum length, confidence threshold
- **Visualization Settings**: Chart size, wordcloud options
- **Output Options**: File format, save path

### Key Configuration Options
```python
# Sentiment analysis settings
SENTIMENT_CONFIG = {
    'batch_size': 16,           # Batch size
    'max_length': 128,          # Maximum text length
    'confidence_threshold': 0.8, # Confidence threshold
    'device': 'auto'            # Device auto-selection
}

# Language detection settings
LANGUAGE_DETECTION_CONFIG = {
    'min_confidence': 0.7,      # Minimum confidence for language detection
    'fallback_language': 'e'    # Default language (English)
}
```

## ğŸ“ Usage Examples

### 1. Analyze Excel File
```bash
# 1. Place Excel file in output/ folder
# 2. Run analysis
python src/main.py your_data.xlsx
```

### 2. Run Analysis with Sample Data
```bash
python src/main.py
```

### 3. Force Create Sample Data
```bash
python src/main.py --sample
```

### 4. Advanced Options
```bash
# Specify output directory
python src/main.py input_file.xlsx -o /path/to/output

# Debug mode
python src/main.py input_file.xlsx --debug

# Show help
python src/main.py --help
```

## ğŸŒ Google Colab Support

The `src/colab/` folder contains Google Colab notebooks for each language:

- **ğŸ‡°ğŸ‡· Korean**: `korean_sentiment_analysis.ipynb`
- **ğŸ‡¨ğŸ‡³ Chinese**: `chinese_sentiment_analysis.ipynb`
- **ğŸ‡ºğŸ‡¸ English**: `english_sentiment_analysis.ipynb`
- **ğŸ‡¯ğŸ‡µ Japanese**: `japanese_sentiment_analysis.ipynb`

### Colab Usage
1. Upload the desired language notebook to Colab
2. Install required packages
3. Upload Excel file
4. Execute code to perform sentiment analysis
5. Download results

## ğŸ“‹ System Requirements

### Basic Requirements
- **Python**: 3.8+ (Recommended: 3.11+)
- **Memory**: 4GB+ RAM recommended
- **Internet**: Required for model download on first run
- **GPU**: Optional (CUDA support)

### Supported Operating Systems
- Windows 10+
- macOS 10.15+
- Ubuntu 18.04+

### GPU Support (Optional)
```bash
# Install PyTorch with CUDA 11.8+ support
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

## ğŸ” Key Features in Detail

### 1. Automatic Language Detection
- Automatic language detection from text input
- Confidence-based language selection
- Fallback language support

### 2. Multi-Model Support
- Language-optimized models for each language
- Alternative model and fallback model support
- Model caching for performance optimization

### 3. Batch Processing
- Efficient processing of large datasets
- Memory usage optimization
- Progress display and logging

### 4. Result Visualization
- High-quality charts based on matplotlib
- Language-specific color themes
- Wordcloud generation
- Comparative analysis charts

## ğŸš¨ Important Notes

- **First Run**: Transformers models are automatically downloaded (internet connection required)
- **GPU Usage**: CUDA version verification required
- **Windows Environment**: Visual C++ build tools may be required for some package installations
- **Memory**: Sufficient RAM required for large dataset processing

## ğŸ¤ Contributing

This system is designed for both beginners and experts. Feel free to modify and improve the code according to your needs.

### How to Contribute
1. Fork the project
2. Create a feature branch
3. Modify code and test
4. Create a Pull Request

## ğŸ“„ License

Open source project for educational and research purposes.

## ğŸ“ Support and Issues

For project-related questions or bug reports, please submit them through GitHub Issues.

---

**ğŸ‰ Thank you for using the Multi-Language Sentiment Analysis System!**


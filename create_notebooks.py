#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Jupyter 노트북 파일들을 생성하는 스크립트
"""

import json
import os

def create_korean_notebook():
    """한국어 감성분석 노트북 생성"""
    notebook = {
        "cells": [
            {
                "cell_type": "markdown",
                "metadata": {"id": "korean-title"},
                "source": [
                    "# 🇰🇷 한국어 감성분석 (Korean Sentiment Analysis)\n\n",
                    "Google Colab에서 실행 가능한 한국어 텍스트 감성분석 시스템입니다.\n\n",
                    "## 📋 기능\n",
                    "- Excel 파일에서 한국어 텍스트 읽기\n",
                    "- 한국어 전용 감성분석 모델 사용\n",
                    "- 결과를 Excel 파일로 저장\n\n",
                    "## 🚀 사용법\n",
                    "1. Excel 파일을 업로드 (텍스트 컬럼 포함)\n",
                    "2. 코드 실행\n",
                    "3. 결과 다운로드"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "install-deps"},
                "source": ["## 📦 필요한 패키지 설치"]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {"id": "install-packages"},
                "outputs": [],
                "source": [
                    "# 필요한 패키지 설치\n",
                    "!pip install torch transformers pandas openpyxl matplotlib seaborn wordcloud"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "import-libs"},
                "source": ["## 📚 라이브러리 임포트"]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {"id": "imports"},
                "outputs": [],
                "source": [
                    "import torch\n",
                    "import pandas as pd\n",
                    "import numpy as np\n",
                    "import matplotlib.pyplot as plt\n",
                    "import seaborn as sns\n",
                    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
                    "from wordcloud import WordCloud\n",
                    "import warnings\n",
                    "import logging\n",
                    "from google.colab import files\n",
                    "from io import BytesIO\n",
                    "\n",
                    "# 경고 메시지 차단\n",
                    "warnings.filterwarnings('ignore')\n",
                    "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
                    "\n",
                    "# 한글 폰트 설정\n",
                    "plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial Unicode MS']\n",
                    "plt.rcParams['axes.unicode_minus'] = False\n",
                    "\n",
                    "print(\"✅ 라이브러리 로드 완료\")"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "model-loading"},
                "source": ["## 🤖 한국어 감성분석 모델 로드"]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {"id": "load-model"},
                "outputs": [],
                "source": [
                    "# 한국어 감성분석 모델 (가장 정확한 모델)\n",
                    "model_name = \"snunlp/KR-FinBert-SC\"\n",
                    "\n",
                    "print(f\"🔄 모델 로딩 중: {model_name}\")\n",
                    "\n",
                    "# 토크나이저와 모델 로드\n",
                    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
                    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
                    "\n",
                    "# GPU 사용 가능시 GPU 사용\n",
                    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                    "model.to(device)\n",
                    "\n",
                    "print(f\"✅ 모델 로드 완료! 디바이스: {device}\")\n",
                    "print(f\"📊 모델: {model_name}\")"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "file-upload"},
                "source": ["## 📁 Excel 파일 업로드"]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {"id": "upload-file"},
                "outputs": [],
                "source": [
                    "# Excel 파일 업로드\n",
                    "print(\"📁 Excel 파일을 업로드해주세요...\")\n",
                    "uploaded = files.upload()\n",
                    "\n",
                    "if not uploaded:\n",
                    "    print(\"❌ 파일이 업로드되지 않았습니다.\")\n",
                    "else:\n",
                    "    # 첫 번째 파일 사용\n",
                    "    filename = list(uploaded.keys())[0]\n",
                    "    print(f\"✅ 파일 업로드 완료: {filename}\")\n",
                    "    \n",
                    "    # Excel 파일 읽기\n",
                    "    try:\n",
                    "        df = pd.read_excel(BytesIO(uploaded[filename]))\n",
                    "        print(f\"📊 Excel 파일 읽기 성공: {len(df)} 행, {len(df.columns)} 컬럼\")\n",
                    "        print(f\"📋 컬럼명: {list(df.columns)}\")\n",
                    "        print(\"\\n🔍 데이터 미리보기:\")\n",
                    "        display(df.head())\n",
                    "    except Exception as e:\n",
                    "        print(f\"❌ Excel 파일 읽기 실패: {str(e)}\")"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "text-column"},
                "source": ["## 📝 텍스트 컬럼 선택"]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {"id": "select-text-column"},
                "outputs": [],
                "source": [
                    "# 텍스트 컬럼 찾기\n",
                    "text_columns = ['comment', '댓글', 'review', 'text', 'comments', '텍스트', '내용']\n",
                    "text_column = None\n",
                    "\n",
                    "for col in df.columns:\n",
                    "    if col.lower() in [tc.lower() for tc in text_columns]:\n",
                    "        text_column = col\n",
                    "        break\n",
                    "\n",
                    "if text_column is None:\n",
                    "    # 컬럼 내용으로 추정\n",
                    "    for col in df.columns:\n",
                    "        if df[col].dtype == 'object':\n",
                    "            sample_data = df[col].dropna().head(5)\n",
                    "            if len(sample_data) > 0:\n",
                    "                avg_length = sample_data.astype(str).str.len().mean()\n",
                    "                if avg_length > 10:\n",
                    "                    text_column = col\n",
                    "                    break\n",
                    "\n",
                    "if text_column:\n",
                    "    print(f\"✅ 텍스트 컬럼 선택: {text_column}\")\n",
                    "    print(f\"📝 텍스트 개수: {len(df[text_column].dropna())}\")\n",
                    "    print(\"\\n🔍 텍스트 샘플:\")\n",
                    "    for i, text in enumerate(df[text_column].dropna().head(3)):\n",
                    "        print(f\"{i+1}. {text[:100]}{'...' if len(str(text)) > 100 else ''}\")\n",
                    "else:\n",
                    "    print(\"❌ 텍스트 컬럼을 찾을 수 없습니다.\")\n",
                    "    print(\"사용 가능한 컬럼:\")\n",
                    "    for col in df.columns:\n",
                    "        print(f\"- {col} ({df[col].dtype})\")"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "sentiment-analysis"},
                "source": ["## 🧠 감성분석 실행"]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {"id": "run-analysis"},
                "outputs": [],
                "source": [
                    "def analyze_sentiment(texts, tokenizer, model, device):\n",
                    "    \"\"\"한국어 텍스트 감성분석\"\"\"\n",
                    "    results = []\n",
                    "    batch_size = 16\n",
                    "    \n",
                    "    # 라벨 정의\n",
                    "    labels = [\"negative\", \"neutral\", \"positive\"]\n",
                    "    \n",
                    "    for i in range(0, len(texts), batch_size):\n",
                    "        batch_texts = texts[i:i+batch_size]\n",
                    "        \n",
                    "        # 토크나이징\n",
                    "        inputs = tokenizer(batch_texts, padding=True, truncation=True, \n",
                    "                          return_tensors=\"pt\", max_length=128).to(device)\n",
                    "        \n",
                    "        with torch.no_grad():\n",
                    "            outputs = model(**inputs)\n",
                    "            logits = outputs.logits\n",
                    "            probs = torch.softmax(logits, dim=-1)\n",
                    "            \n",
                    "            for j, prob in enumerate(probs):\n",
                    "                max_idx = torch.argmax(prob).item()\n",
                    "                confidence = prob[max_idx].item()\n",
                    "                \n",
                    "                results.append({\n",
                    "                    'text': batch_texts[j],\n",
                    "                    'sentiment_label': labels[max_idx],\n",
                    "                    'sentiment_confidence': confidence,\n",
                    "                    'negative_prob': prob[0].item(),\n",
                    "                    'neutral_prob': prob[1].item(),\n",
                    "                    'positive_prob': prob[2].item()\n",
                    "                })\n",
                    "    \n",
                    "    return results\n",
                    "\n",
                    "# 감성분석 실행\n",
                    "if text_column:\n",
                    "    print(\"🔄 감성분석 실행 중...\")\n",
                    "    \n",
                    "    # 텍스트 데이터 준비\n",
                    "    texts = df[text_column].dropna().astype(str).tolist()\n",
                    "    \n",
                    "    if texts:\n",
                    "        # 감성분석 실행\n",
                    "        results = analyze_sentiment(texts, tokenizer, model, device)\n",
                    "        \n",
                    "        # 결과를 DataFrame으로 변환\n",
                    "        results_df = pd.DataFrame(results)\n",
                    "        \n",
                    "        print(f\"✅ 감성분석 완료: {len(results_df)} 텍스트 분석\")\n",
                    "        \n",
                    "        # 결과 미리보기\n",
                    "        print(\"\\n🔍 감성분석 결과 미리보기:\")\n",
                    "        display(results_df.head())\n",
                    "        \n",
                    "        # 감성 분포\n",
                    "        sentiment_counts = results_df['sentiment_label'].value_counts()\n",
                    "        print(\"\\n📊 감성 분포:\")\n",
                    "        for sentiment, count in sentiment_counts.items():\n",
                    "            percentage = (count / len(results_df)) * 100\n",
                    "            print(f\"- {sentiment}: {count}개 ({percentage:.1f}%)\")\n",
                    "    else:\n",
                    "        print(\"❌ 분석할 텍스트가 없습니다.\")\n",
                    "else:\n",
                    "    print(\"❌ 텍스트 컬럼이 선택되지 않았습니다.\")"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "visualization"},
                "source": ["## 📊 시각화"]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {"id": "create-charts"},
                "outputs": [],
                "source": [
                    "if 'results_df' in locals() and not results_df.empty:\n",
                    "    # 1. 감성 분포 막대 차트\n",
                    "    plt.figure(figsize=(10, 6))\n",
                    "    sentiment_counts = results_df['sentiment_label'].value_counts()\n",
                    "    colors = ['#F44336', '#9E9E9E', '#4CAF50']  # 빨강, 회색, 초록\n",
                    "    \n",
                    "    bars = plt.bar(sentiment_counts.index, sentiment_counts.values, color=colors, alpha=0.8)\n",
                    "    plt.title('한국어 텍스트 감성분석 결과', fontsize=16, fontweight='bold')\n",
                    "    plt.xlabel('감성', fontsize=12)\n",
                    "    plt.ylabel('텍스트 수', fontsize=12)\n",
                    "    \n",
                    "    # 값 표시\n",
                    "    for bar, count in zip(bars, sentiment_counts.values):\n",
                    "        plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.5,\n",
                    "                str(count), ha='center', va='bottom', fontweight='bold')\n",
                    "    \n",
                    "    plt.tight_layout()\n",
                    "    plt.show()\n",
                    "    \n",
                    "    # 2. 감성 분포 파이 차트\n",
                    "    plt.figure(figsize=(8, 8))\n",
                    "    plt.pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%',\n",
                    "            colors=colors, startangle=90)\n",
                    "    plt.title('감성 분포 비율', fontsize=16, fontweight='bold')\n",
                    "    plt.axis('equal')\n",
                    "    plt.show()\n",
                    "    \n",
                    "    # 3. 신뢰도 분포 히스토그램\n",
                    "    plt.figure(figsize=(10, 6))\n",
                    "    plt.hist(results_df['sentiment_confidence'], bins=20, alpha=0.7, color='skyblue')\n",
                    "    plt.title('감성분석 신뢰도 분포', fontsize=16, fontweight='bold')\n",
                    "    plt.xlabel('신뢰도', fontsize=12)\n",
                    "    plt.ylabel('빈도', fontsize=12)\n",
                    "    \n",
                    "    # 평균선 추가\n",
                    "    mean_confidence = results_df['sentiment_confidence'].mean()\n",
                    "    plt.axvline(mean_confidence, color='red', linestyle='--', \n",
                    "                label=f'평균: {mean_confidence:.3f}')\n",
                    "    plt.legend()\n",
                    "    plt.grid(True, alpha=0.3)\n",
                    "    plt.tight_layout()\n",
                    "    plt.show()\n",
                    "    \n",
                    "    # 4. 워드클라우드 (긍정적 텍스트만)\n",
                    "    positive_texts = results_df[results_df['sentiment_label'] == 'positive']['text'].tolist()\n",
                    "    if positive_texts:\n",
                    "        combined_text = ' '.join(positive_texts)\n",
                    "        \n",
                    "        # 특수문자 제거 및 전처리\n",
                    "        import re\n",
                    "        processed_text = re.sub(r'[^\\w\\s]', ' ', combined_text)\n",
                    "        processed_text = re.sub(r'\\s+', ' ', processed_text)\n",
                    "        \n",
                    "        if processed_text.strip():\n",
                    "            wordcloud = WordCloud(\n",
                    "                width=800, height=400,\n",
                    "                background_color='white',\n",
                    "                max_words=100,\n",
                    "                min_font_size=12,\n",
                    "                relative_scaling=0.5,\n",
                    "                colormap='viridis'\n",
                    "            ).generate(processed_text)\n",
                    "            \n",
                    "            plt.figure(figsize=(16, 8))\n",
                    "            plt.imshow(wordcloud, interpolation='bilinear')\n",
                    "            plt.axis('off')\n",
                    "            plt.title('긍정적 텍스트 워드클라우드', fontsize=20, fontweight='bold')\n",
                    "            plt.tight_layout()\n",
                    "            plt.show()\n",
                    "else:\n",
                    "    print(\"❌ 시각화할 결과가 없습니다.\")"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "save-results"},
                "source": ["## 💾 결과 저장"]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {"id": "save-excel"},
                "outputs": [],
                "source": [
                    "if 'results_df' in locals() and not results_df.empty:\n",
                    "    # 원본 데이터와 결과 합치기\n",
                    "    final_df = df.copy()\n",
                    "    \n",
                    "    # 결과 컬럼 추가\n",
                    "    for col in results_df.columns:\n",
                    "        if col != 'text':  # text 컬럼은 제외 (중복)\n",
                    "            final_df[col] = results_df[col]\n",
                    "    \n",
                    "    # 결과 파일명 생성\n",
                    "    output_filename = f\"korean_sentiment_analysis_result_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
                    "    \n",
                    "    # Excel 파일로 저장\n",
                    "    with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
                    "        # 전체 결과\n",
                    "        final_df.to_excel(writer, sheet_name='감성분석_결과', index=False)\n",
                    "        \n",
                    "        # 감성별 요약\n",
                    "        sentiment_summary = results_df['sentiment_label'].value_counts().reset_index()\n",
                    "        sentiment_summary.columns = ['감성', '개수']\n",
                    "        sentiment_summary['비율(%)'] = (sentiment_summary['개수'] / len(results_df) * 100).round(1)\n",
                    "        sentiment_summary.to_excel(writer, sheet_name='감성_요약', index=False)\n",
                    "        \n",
                    "        # 상세 결과\n",
                    "        results_df.to_excel(writer, sheet_name='상세_결과', index=False)\n",
                    "    \n",
                    "    print(f\"✅ 결과 저장 완료: {output_filename}\")\n",
                    "    print(f\"📊 총 {len(final_df)} 행의 데이터가 분석되었습니다.\")\n",
                    "    \n",
                    "    # 파일 다운로드\n",
                    "    files.download(output_filename)\n",
                    "    \n",
                    "    # 결과 미리보기\n",
                    "    print(\"\\n🔍 최종 결과 미리보기:\")\n",
                    "    display(final_df.head())\n",
                    "else:\n",
                    "    print(\"❌ 저장할 결과가 없습니다.\")"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "summary"},
                "source": [
                    "## 🎯 요약\n\n",
                    "✅ **한국어 감성분석 완료!**\n\n",
                    "### 📊 분석 결과:\n",
                    "- **총 텍스트 수**: {len(results_df) if 'results_df' in locals() else 'N/A'}\n",
                    "- **감성 분포**: 위 차트 참조\n",
                    "- **평균 신뢰도**: {results_df['sentiment_confidence'].mean():.3f if 'results_df' in locals() else 'N/A'}\n\n",
                    "### 📁 다운로드 파일:\n",
                    "- Excel 결과 파일이 자동으로 다운로드됩니다\n",
                    "- 3개 시트 포함: 감성분석_결과, 감성_요약, 상세_결과\n\n",
                    "### 💡 팁:\n",
                    "- 더 정확한 결과를 원한다면 텍스트를 더 많이 제공하세요\n",
                    "- 한국어 텍스트가 아닌 경우 다른 언어용 파일을 사용하세요"
                ]
            }
        ],
        "metadata": {
            "colab": {"name": "한국어 감성분석", "provenance": []},
            "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
            "language_info": {
                "codemirror_mode": {"name": "ipython", "version": 3},
                "file_extension": ".py",
                "mimetype": "text/x-python",
                "name": "python",
                "nbconvert_exporter": "python",
                "pygments_lexer": "ipython3",
                "version": "3.8.5"
            }
        },
        "nbformat": 4,
        "nbformat_minor": 4
    }
    
    with open('src/colab/korean_sentiment_analysis.ipynb', 'w', encoding='utf-8') as f:
        json.dump(notebook, f, ensure_ascii=False, indent=2)
    
    print("한국어 노트북 파일 생성 완료!")

if __name__ == "__main__":
    create_korean_notebook()

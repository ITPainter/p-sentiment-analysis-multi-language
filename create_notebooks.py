#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Jupyter ë…¸íŠ¸ë¶ íŒŒì¼ë“¤ì„ ìƒì„±í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import json
import os

def create_korean_notebook():
    """í•œêµ­ì–´ ê°ì„±ë¶„ì„ ë…¸íŠ¸ë¶ ìƒì„±"""
    notebook = {
        "cells": [
            {
                "cell_type": "markdown",
                "metadata": {"id": "korean-title"},
                "source": [
                    "# ğŸ‡°ğŸ‡· í•œêµ­ì–´ ê°ì„±ë¶„ì„ (Korean Sentiment Analysis)\n\n",
                    "Google Colabì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ê°ì„±ë¶„ì„ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\n\n",
                    "## ğŸ“‹ ê¸°ëŠ¥\n",
                    "- Excel íŒŒì¼ì—ì„œ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì½ê¸°\n",
                    "- í•œêµ­ì–´ ì „ìš© ê°ì„±ë¶„ì„ ëª¨ë¸ ì‚¬ìš©\n",
                    "- ê²°ê³¼ë¥¼ Excel íŒŒì¼ë¡œ ì €ì¥\n\n",
                    "## ğŸš€ ì‚¬ìš©ë²•\n",
                    "1. Excel íŒŒì¼ì„ ì—…ë¡œë“œ (í…ìŠ¤íŠ¸ ì»¬ëŸ¼ í¬í•¨)\n",
                    "2. ì½”ë“œ ì‹¤í–‰\n",
                    "3. ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "install-deps"},
                "source": ["## ğŸ“¦ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜"]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {"id": "install-packages"},
                "outputs": [],
                "source": [
                    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
                    "!pip install torch transformers pandas openpyxl matplotlib seaborn wordcloud"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "import-libs"},
                "source": ["## ğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {"id": "imports"},
                "outputs": [],
                "source": [
                    "import torch\n",
                    "import pandas as pd\n",
                    "import numpy as np\n",
                    "import matplotlib.pyplot as plt\n",
                    "import seaborn as sns\n",
                    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
                    "from wordcloud import WordCloud\n",
                    "import warnings\n",
                    "import logging\n",
                    "from google.colab import files\n",
                    "from io import BytesIO\n",
                    "\n",
                    "# ê²½ê³  ë©”ì‹œì§€ ì°¨ë‹¨\n",
                    "warnings.filterwarnings('ignore')\n",
                    "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
                    "\n",
                    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
                    "plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial Unicode MS']\n",
                    "plt.rcParams['axes.unicode_minus'] = False\n",
                    "\n",
                    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "model-loading"},
                "source": ["## ğŸ¤– í•œêµ­ì–´ ê°ì„±ë¶„ì„ ëª¨ë¸ ë¡œë“œ"]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {"id": "load-model"},
                "outputs": [],
                "source": [
                    "# í•œêµ­ì–´ ê°ì„±ë¶„ì„ ëª¨ë¸ (ê°€ì¥ ì •í™•í•œ ëª¨ë¸)\n",
                    "model_name = \"snunlp/KR-FinBert-SC\"\n",
                    "\n",
                    "print(f\"ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}\")\n",
                    "\n",
                    "# í† í¬ë‚˜ì´ì €ì™€ ëª¨ë¸ ë¡œë“œ\n",
                    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
                    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
                    "\n",
                    "# GPU ì‚¬ìš© ê°€ëŠ¥ì‹œ GPU ì‚¬ìš©\n",
                    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                    "model.to(device)\n",
                    "\n",
                    "print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! ë””ë°”ì´ìŠ¤: {device}\")\n",
                    "print(f\"ğŸ“Š ëª¨ë¸: {model_name}\")"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "file-upload"},
                "source": ["## ğŸ“ Excel íŒŒì¼ ì—…ë¡œë“œ"]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {"id": "upload-file"},
                "outputs": [],
                "source": [
                    "# Excel íŒŒì¼ ì—…ë¡œë“œ\n",
                    "print(\"ğŸ“ Excel íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”...\")\n",
                    "uploaded = files.upload()\n",
                    "\n",
                    "if not uploaded:\n",
                    "    print(\"âŒ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
                    "else:\n",
                    "    # ì²« ë²ˆì§¸ íŒŒì¼ ì‚¬ìš©\n",
                    "    filename = list(uploaded.keys())[0]\n",
                    "    print(f\"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {filename}\")\n",
                    "    \n",
                    "    # Excel íŒŒì¼ ì½ê¸°\n",
                    "    try:\n",
                    "        df = pd.read_excel(BytesIO(uploaded[filename]))\n",
                    "        print(f\"ğŸ“Š Excel íŒŒì¼ ì½ê¸° ì„±ê³µ: {len(df)} í–‰, {len(df.columns)} ì»¬ëŸ¼\")\n",
                    "        print(f\"ğŸ“‹ ì»¬ëŸ¼ëª…: {list(df.columns)}\")\n",
                    "        print(\"\\nğŸ” ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
                    "        display(df.head())\n",
                    "    except Exception as e:\n",
                    "        print(f\"âŒ Excel íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}\")"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "text-column"},
                "source": ["## ğŸ“ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì„ íƒ"]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {"id": "select-text-column"},
                "outputs": [],
                "source": [
                    "# í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì°¾ê¸°\n",
                    "text_columns = ['comment', 'ëŒ“ê¸€', 'review', 'text', 'comments', 'í…ìŠ¤íŠ¸', 'ë‚´ìš©']\n",
                    "text_column = None\n",
                    "\n",
                    "for col in df.columns:\n",
                    "    if col.lower() in [tc.lower() for tc in text_columns]:\n",
                    "        text_column = col\n",
                    "        break\n",
                    "\n",
                    "if text_column is None:\n",
                    "    # ì»¬ëŸ¼ ë‚´ìš©ìœ¼ë¡œ ì¶”ì •\n",
                    "    for col in df.columns:\n",
                    "        if df[col].dtype == 'object':\n",
                    "            sample_data = df[col].dropna().head(5)\n",
                    "            if len(sample_data) > 0:\n",
                    "                avg_length = sample_data.astype(str).str.len().mean()\n",
                    "                if avg_length > 10:\n",
                    "                    text_column = col\n",
                    "                    break\n",
                    "\n",
                    "if text_column:\n",
                    "    print(f\"âœ… í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì„ íƒ: {text_column}\")\n",
                    "    print(f\"ğŸ“ í…ìŠ¤íŠ¸ ê°œìˆ˜: {len(df[text_column].dropna())}\")\n",
                    "    print(\"\\nğŸ” í…ìŠ¤íŠ¸ ìƒ˜í”Œ:\")\n",
                    "    for i, text in enumerate(df[text_column].dropna().head(3)):\n",
                    "        print(f\"{i+1}. {text[:100]}{'...' if len(str(text)) > 100 else ''}\")\n",
                    "else:\n",
                    "    print(\"âŒ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
                    "    print(\"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼:\")\n",
                    "    for col in df.columns:\n",
                    "        print(f\"- {col} ({df[col].dtype})\")"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "sentiment-analysis"},
                "source": ["## ğŸ§  ê°ì„±ë¶„ì„ ì‹¤í–‰"]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {"id": "run-analysis"},
                "outputs": [],
                "source": [
                    "def analyze_sentiment(texts, tokenizer, model, device):\n",
                    "    \"\"\"í•œêµ­ì–´ í…ìŠ¤íŠ¸ ê°ì„±ë¶„ì„\"\"\"\n",
                    "    results = []\n",
                    "    batch_size = 16\n",
                    "    \n",
                    "    # ë¼ë²¨ ì •ì˜\n",
                    "    labels = [\"negative\", \"neutral\", \"positive\"]\n",
                    "    \n",
                    "    for i in range(0, len(texts), batch_size):\n",
                    "        batch_texts = texts[i:i+batch_size]\n",
                    "        \n",
                    "        # í† í¬ë‚˜ì´ì§•\n",
                    "        inputs = tokenizer(batch_texts, padding=True, truncation=True, \n",
                    "                          return_tensors=\"pt\", max_length=128).to(device)\n",
                    "        \n",
                    "        with torch.no_grad():\n",
                    "            outputs = model(**inputs)\n",
                    "            logits = outputs.logits\n",
                    "            probs = torch.softmax(logits, dim=-1)\n",
                    "            \n",
                    "            for j, prob in enumerate(probs):\n",
                    "                max_idx = torch.argmax(prob).item()\n",
                    "                confidence = prob[max_idx].item()\n",
                    "                \n",
                    "                results.append({\n",
                    "                    'text': batch_texts[j],\n",
                    "                    'sentiment_label': labels[max_idx],\n",
                    "                    'sentiment_confidence': confidence,\n",
                    "                    'negative_prob': prob[0].item(),\n",
                    "                    'neutral_prob': prob[1].item(),\n",
                    "                    'positive_prob': prob[2].item()\n",
                    "                })\n",
                    "    \n",
                    "    return results\n",
                    "\n",
                    "# ê°ì„±ë¶„ì„ ì‹¤í–‰\n",
                    "if text_column:\n",
                    "    print(\"ğŸ”„ ê°ì„±ë¶„ì„ ì‹¤í–‰ ì¤‘...\")\n",
                    "    \n",
                    "    # í…ìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„\n",
                    "    texts = df[text_column].dropna().astype(str).tolist()\n",
                    "    \n",
                    "    if texts:\n",
                    "        # ê°ì„±ë¶„ì„ ì‹¤í–‰\n",
                    "        results = analyze_sentiment(texts, tokenizer, model, device)\n",
                    "        \n",
                    "        # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
                    "        results_df = pd.DataFrame(results)\n",
                    "        \n",
                    "        print(f\"âœ… ê°ì„±ë¶„ì„ ì™„ë£Œ: {len(results_df)} í…ìŠ¤íŠ¸ ë¶„ì„\")\n",
                    "        \n",
                    "        # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°\n",
                    "        print(\"\\nğŸ” ê°ì„±ë¶„ì„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°:\")\n",
                    "        display(results_df.head())\n",
                    "        \n",
                    "        # ê°ì„± ë¶„í¬\n",
                    "        sentiment_counts = results_df['sentiment_label'].value_counts()\n",
                    "        print(\"\\nğŸ“Š ê°ì„± ë¶„í¬:\")\n",
                    "        for sentiment, count in sentiment_counts.items():\n",
                    "            percentage = (count / len(results_df)) * 100\n",
                    "            print(f\"- {sentiment}: {count}ê°œ ({percentage:.1f}%)\")\n",
                    "    else:\n",
                    "        print(\"âŒ ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
                    "else:\n",
                    "    print(\"âŒ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "visualization"},
                "source": ["## ğŸ“Š ì‹œê°í™”"]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {"id": "create-charts"},
                "outputs": [],
                "source": [
                    "if 'results_df' in locals() and not results_df.empty:\n",
                    "    # 1. ê°ì„± ë¶„í¬ ë§‰ëŒ€ ì°¨íŠ¸\n",
                    "    plt.figure(figsize=(10, 6))\n",
                    "    sentiment_counts = results_df['sentiment_label'].value_counts()\n",
                    "    colors = ['#F44336', '#9E9E9E', '#4CAF50']  # ë¹¨ê°•, íšŒìƒ‰, ì´ˆë¡\n",
                    "    \n",
                    "    bars = plt.bar(sentiment_counts.index, sentiment_counts.values, color=colors, alpha=0.8)\n",
                    "    plt.title('í•œêµ­ì–´ í…ìŠ¤íŠ¸ ê°ì„±ë¶„ì„ ê²°ê³¼', fontsize=16, fontweight='bold')\n",
                    "    plt.xlabel('ê°ì„±', fontsize=12)\n",
                    "    plt.ylabel('í…ìŠ¤íŠ¸ ìˆ˜', fontsize=12)\n",
                    "    \n",
                    "    # ê°’ í‘œì‹œ\n",
                    "    for bar, count in zip(bars, sentiment_counts.values):\n",
                    "        plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.5,\n",
                    "                str(count), ha='center', va='bottom', fontweight='bold')\n",
                    "    \n",
                    "    plt.tight_layout()\n",
                    "    plt.show()\n",
                    "    \n",
                    "    # 2. ê°ì„± ë¶„í¬ íŒŒì´ ì°¨íŠ¸\n",
                    "    plt.figure(figsize=(8, 8))\n",
                    "    plt.pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%',\n",
                    "            colors=colors, startangle=90)\n",
                    "    plt.title('ê°ì„± ë¶„í¬ ë¹„ìœ¨', fontsize=16, fontweight='bold')\n",
                    "    plt.axis('equal')\n",
                    "    plt.show()\n",
                    "    \n",
                    "    # 3. ì‹ ë¢°ë„ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨\n",
                    "    plt.figure(figsize=(10, 6))\n",
                    "    plt.hist(results_df['sentiment_confidence'], bins=20, alpha=0.7, color='skyblue')\n",
                    "    plt.title('ê°ì„±ë¶„ì„ ì‹ ë¢°ë„ ë¶„í¬', fontsize=16, fontweight='bold')\n",
                    "    plt.xlabel('ì‹ ë¢°ë„', fontsize=12)\n",
                    "    plt.ylabel('ë¹ˆë„', fontsize=12)\n",
                    "    \n",
                    "    # í‰ê· ì„  ì¶”ê°€\n",
                    "    mean_confidence = results_df['sentiment_confidence'].mean()\n",
                    "    plt.axvline(mean_confidence, color='red', linestyle='--', \n",
                    "                label=f'í‰ê· : {mean_confidence:.3f}')\n",
                    "    plt.legend()\n",
                    "    plt.grid(True, alpha=0.3)\n",
                    "    plt.tight_layout()\n",
                    "    plt.show()\n",
                    "    \n",
                    "    # 4. ì›Œë“œí´ë¼ìš°ë“œ (ê¸ì •ì  í…ìŠ¤íŠ¸ë§Œ)\n",
                    "    positive_texts = results_df[results_df['sentiment_label'] == 'positive']['text'].tolist()\n",
                    "    if positive_texts:\n",
                    "        combined_text = ' '.join(positive_texts)\n",
                    "        \n",
                    "        # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì „ì²˜ë¦¬\n",
                    "        import re\n",
                    "        processed_text = re.sub(r'[^\\w\\s]', ' ', combined_text)\n",
                    "        processed_text = re.sub(r'\\s+', ' ', processed_text)\n",
                    "        \n",
                    "        if processed_text.strip():\n",
                    "            wordcloud = WordCloud(\n",
                    "                width=800, height=400,\n",
                    "                background_color='white',\n",
                    "                max_words=100,\n",
                    "                min_font_size=12,\n",
                    "                relative_scaling=0.5,\n",
                    "                colormap='viridis'\n",
                    "            ).generate(processed_text)\n",
                    "            \n",
                    "            plt.figure(figsize=(16, 8))\n",
                    "            plt.imshow(wordcloud, interpolation='bilinear')\n",
                    "            plt.axis('off')\n",
                    "            plt.title('ê¸ì •ì  í…ìŠ¤íŠ¸ ì›Œë“œí´ë¼ìš°ë“œ', fontsize=20, fontweight='bold')\n",
                    "            plt.tight_layout()\n",
                    "            plt.show()\n",
                    "else:\n",
                    "    print(\"âŒ ì‹œê°í™”í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "save-results"},
                "source": ["## ğŸ’¾ ê²°ê³¼ ì €ì¥"]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {"id": "save-excel"},
                "outputs": [],
                "source": [
                    "if 'results_df' in locals() and not results_df.empty:\n",
                    "    # ì›ë³¸ ë°ì´í„°ì™€ ê²°ê³¼ í•©ì¹˜ê¸°\n",
                    "    final_df = df.copy()\n",
                    "    \n",
                    "    # ê²°ê³¼ ì»¬ëŸ¼ ì¶”ê°€\n",
                    "    for col in results_df.columns:\n",
                    "        if col != 'text':  # text ì»¬ëŸ¼ì€ ì œì™¸ (ì¤‘ë³µ)\n",
                    "            final_df[col] = results_df[col]\n",
                    "    \n",
                    "    # ê²°ê³¼ íŒŒì¼ëª… ìƒì„±\n",
                    "    output_filename = f\"korean_sentiment_analysis_result_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
                    "    \n",
                    "    # Excel íŒŒì¼ë¡œ ì €ì¥\n",
                    "    with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
                    "        # ì „ì²´ ê²°ê³¼\n",
                    "        final_df.to_excel(writer, sheet_name='ê°ì„±ë¶„ì„_ê²°ê³¼', index=False)\n",
                    "        \n",
                    "        # ê°ì„±ë³„ ìš”ì•½\n",
                    "        sentiment_summary = results_df['sentiment_label'].value_counts().reset_index()\n",
                    "        sentiment_summary.columns = ['ê°ì„±', 'ê°œìˆ˜']\n",
                    "        sentiment_summary['ë¹„ìœ¨(%)'] = (sentiment_summary['ê°œìˆ˜'] / len(results_df) * 100).round(1)\n",
                    "        sentiment_summary.to_excel(writer, sheet_name='ê°ì„±_ìš”ì•½', index=False)\n",
                    "        \n",
                    "        # ìƒì„¸ ê²°ê³¼\n",
                    "        results_df.to_excel(writer, sheet_name='ìƒì„¸_ê²°ê³¼', index=False)\n",
                    "    \n",
                    "    print(f\"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_filename}\")\n",
                    "    print(f\"ğŸ“Š ì´ {len(final_df)} í–‰ì˜ ë°ì´í„°ê°€ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
                    "    \n",
                    "    # íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
                    "    files.download(output_filename)\n",
                    "    \n",
                    "    # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°\n",
                    "    print(\"\\nğŸ” ìµœì¢… ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°:\")\n",
                    "    display(final_df.head())\n",
                    "else:\n",
                    "    print(\"âŒ ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "summary"},
                "source": [
                    "## ğŸ¯ ìš”ì•½\n\n",
                    "âœ… **í•œêµ­ì–´ ê°ì„±ë¶„ì„ ì™„ë£Œ!**\n\n",
                    "### ğŸ“Š ë¶„ì„ ê²°ê³¼:\n",
                    "- **ì´ í…ìŠ¤íŠ¸ ìˆ˜**: {len(results_df) if 'results_df' in locals() else 'N/A'}\n",
                    "- **ê°ì„± ë¶„í¬**: ìœ„ ì°¨íŠ¸ ì°¸ì¡°\n",
                    "- **í‰ê·  ì‹ ë¢°ë„**: {results_df['sentiment_confidence'].mean():.3f if 'results_df' in locals() else 'N/A'}\n\n",
                    "### ğŸ“ ë‹¤ìš´ë¡œë“œ íŒŒì¼:\n",
                    "- Excel ê²°ê³¼ íŒŒì¼ì´ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤\n",
                    "- 3ê°œ ì‹œíŠ¸ í¬í•¨: ê°ì„±ë¶„ì„_ê²°ê³¼, ê°ì„±_ìš”ì•½, ìƒì„¸_ê²°ê³¼\n\n",
                    "### ğŸ’¡ íŒ:\n",
                    "- ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì›í•œë‹¤ë©´ í…ìŠ¤íŠ¸ë¥¼ ë” ë§ì´ ì œê³µí•˜ì„¸ìš”\n",
                    "- í•œêµ­ì–´ í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° ë‹¤ë¥¸ ì–¸ì–´ìš© íŒŒì¼ì„ ì‚¬ìš©í•˜ì„¸ìš”"
                ]
            }
        ],
        "metadata": {
            "colab": {"name": "í•œêµ­ì–´ ê°ì„±ë¶„ì„", "provenance": []},
            "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
            "language_info": {
                "codemirror_mode": {"name": "ipython", "version": 3},
                "file_extension": ".py",
                "mimetype": "text/x-python",
                "name": "python",
                "nbconvert_exporter": "python",
                "pygments_lexer": "ipython3",
                "version": "3.8.5"
            }
        },
        "nbformat": 4,
        "nbformat_minor": 4
    }
    
    with open('src/colab/korean_sentiment_analysis.ipynb', 'w', encoding='utf-8') as f:
        json.dump(notebook, f, ensure_ascii=False, indent=2)
    
    print("í•œêµ­ì–´ ë…¸íŠ¸ë¶ íŒŒì¼ ìƒì„± ì™„ë£Œ!")

if __name__ == "__main__":
    create_korean_notebook()

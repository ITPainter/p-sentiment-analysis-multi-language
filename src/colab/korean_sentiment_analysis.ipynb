{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "korean-title"
   },
   "source": [
    "# ğŸ‡°ğŸ‡· í•œêµ­ì–´ ê°ì„±ë¶„ì„ (Korean Sentiment Analysis)\n",
    "\n",
    "Google Colabì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ê°ì„±ë¶„ì„ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ“‹ ê¸°ëŠ¥\n",
    "- Excel íŒŒì¼ì—ì„œ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì½ê¸°\n",
    "- í•œêµ­ì–´ ì „ìš© ê°ì„±ë¶„ì„ ëª¨ë¸ ì‚¬ìš©\n",
    "- ê²°ê³¼ë¥¼ Excel íŒŒì¼ë¡œ ì €ì¥\n",
    "\n",
    "## ğŸš€ ì‚¬ìš©ë²•\n",
    "1. Excel íŒŒì¼ì„ ì—…ë¡œë“œ (í…ìŠ¤íŠ¸ ì»¬ëŸ¼ í¬í•¨)\n",
    "2. ì½”ë“œ ì‹¤í–‰\n",
    "3. ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install-deps"
   },
   "source": [
    "## ğŸ“¦ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-packages"
   },
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install torch transformers pandas openpyxl matplotlib seaborn wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports"
   },
   "source": [
    "## ğŸ”§ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-libraries"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model-loading"
   },
   "source": [
    "## ğŸ¤– í•œêµ­ì–´ ê°ì„±ë¶„ì„ ëª¨ë¸ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-model"
   },
   "outputs": [],
   "source": [
    "# í•œêµ­ì–´ ê°ì„±ë¶„ì„ ëª¨ë¸ ë¡œë“œ\n",
    "model_name = \"snunlp/KR-FinBert-SC\"\n",
    "\n",
    "print(f\"ğŸ“¥ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘: {model_name}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# GPU ì‚¬ìš© ê°€ëŠ¥ì‹œ GPU ì‚¬ìš©\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì¥ì¹˜: {device}\")\n",
    "print(f\"ğŸ“Š ëª¨ë¸: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "file-upload"
   },
   "source": [
    "## ğŸ“ Excel íŒŒì¼ ì—…ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload-file"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"ğŸ“ Excel íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# ì—…ë¡œë“œëœ íŒŒì¼ëª… í™•ì¸\n",
    "file_name = list(uploaded.keys())[0]\n",
    "print(f\"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "read-excel"
   },
   "source": [
    "## ğŸ“Š Excel íŒŒì¼ ì½ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "read-excel-file"
   },
   "outputs": [],
   "source": [
    "# Excel íŒŒì¼ ì½ê¸°\n",
    "df = pd.read_excel(file_name)\n",
    "print(f\"ğŸ“Š ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)} í–‰\")\n",
    "print(f\"ğŸ“‹ ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "print(\"\\nğŸ” ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "select-column"
   },
   "source": [
    "## ğŸ¯ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì„ íƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "select-text-column"
   },
   "outputs": [],
   "source": [
    "# í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì„ íƒ (ìë™ ê°ì§€)\n",
    "text_columns = []\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':  # ë¬¸ìì—´ íƒ€ì… ì»¬ëŸ¼\n",
    "        text_columns.append(col)\n",
    "\n",
    "if text_columns:\n",
    "    text_column = text_columns[0]  # ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì‚¬ìš©\n",
    "    print(f\"âœ… í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì„ íƒ: {text_column}\")\n",
    "else:\n",
    "    print(\"âŒ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    text_column = None\n",
    "\n",
    "if text_column:\n",
    "    print(f\"\\nğŸ“ í…ìŠ¤íŠ¸ ìƒ˜í”Œ:\")\n",
    "    for i, text in enumerate(df[text_column].head()):\n",
    "        print(f\"{i+1}. {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sentiment-analysis"
   },
   "source": [
    "## ğŸ§  ê°ì„±ë¶„ì„ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-sentiment-analysis"
   },
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ì˜ ê°ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤.\"\"\"\n",
    "    if pd.isna(text) or str(text).strip() == \"\":\n",
    "        return \"neutral\", 0.0\n",
    "    \n",
    "    # í† í°í™”\n",
    "    inputs = tokenizer(str(text), return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # ì˜ˆì¸¡\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probabilities = torch.softmax(outputs.logits, dim=-1)\n",
    "        \n",
    "    # ê²°ê³¼ í•´ì„\n",
    "    scores = probabilities[0].cpu().numpy()\n",
    "    \n",
    "    # KR-FinBert-SC: [negative, positive, neutral]\n",
    "    labels = [\"negative\", \"positive\", \"neutral\"]\n",
    "    predicted_label = labels[np.argmax(scores)]\n",
    "    confidence = float(np.max(scores))\n",
    "    \n",
    "    return predicted_label, confidence\n",
    "\n",
    "# ê°ì„±ë¶„ì„ ì‹¤í–‰\n",
    "print(\"ğŸ§  ê°ì„±ë¶„ì„ ì‹¤í–‰ ì¤‘...\")\n",
    "results = []\n",
    "\n",
    "for idx, text in enumerate(df[text_column]):\n",
    "    sentiment, confidence = analyze_sentiment(text)\n",
    "    results.append({\n",
    "        'text': text,\n",
    "        'sentiment': sentiment,\n",
    "        'confidence': confidence\n",
    "    })\n",
    "    \n",
    "    if (idx + 1) % 10 == 0:\n",
    "        print(f\"ì§„í–‰ë¥ : {idx + 1}/{len(df)} ({((idx + 1)/len(df)*100):.1f}%)\")\n",
    "\n",
    "print(\"âœ… ê°ì„±ë¶„ì„ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results-display"
   },
   "source": [
    "## ğŸ“Š ê²°ê³¼ í‘œì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show-results"
   },
   "outputs": [],
   "source": [
    "# ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df['original_text'] = df[text_column]\n",
    "\n",
    "# ê°ì„±ë³„ í†µê³„\n",
    "sentiment_counts = results_df['sentiment'].value_counts()\n",
    "print(\"ğŸ“Š ê°ì„±ë¶„ì„ ê²°ê³¼:\")\n",
    "print(f\"ì´ í…ìŠ¤íŠ¸ ìˆ˜: {len(results_df)}\")\n",
    "print(\"\\nê°ì„±ë³„ ë¶„í¬:\")\n",
    "for sentiment, count in sentiment_counts.items():\n",
    "    percentage = (count / len(results_df)) * 100\n",
    "    print(f\"- {sentiment}: {count}ê°œ ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\nğŸ” ìƒì„¸ ê²°ê³¼:\")\n",
    "display(results_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization"
   },
   "source": [
    "## ğŸ“ˆ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create-charts"
   },
   "outputs": [],
   "source": [
    "# 1. ê°ì„±ë³„ ë§‰ëŒ€ ì°¨íŠ¸\n",
    "plt.figure(figsize=(10, 6))\n",
    "sentiment_counts.plot(kind='bar', color=['#ff6b6b', '#4ecdc4', '#45b7d1'])\n",
    "plt.title('í•œêµ­ì–´ í…ìŠ¤íŠ¸ ê°ì„±ë¶„ì„ ê²°ê³¼', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('ê°ì„±')\n",
    "plt.ylabel('í…ìŠ¤íŠ¸ ìˆ˜')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. ê°ì„±ë³„ íŒŒì´ ì°¨íŠ¸\n",
    "plt.figure(figsize=(8, 8))\n",
    "colors = ['#ff6b6b', '#4ecdc4', '#45b7d1']\n",
    "plt.pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%', colors=colors)\n",
    "plt.title('ê°ì„±ë³„ ë¹„ìœ¨', fontsize=16, fontweight='bold')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "# 3. ì‹ ë¢°ë„ ë¶„í¬\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(results_df['confidence'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('ê°ì„±ë¶„ì„ ì‹ ë¢°ë„ ë¶„í¬', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('ì‹ ë¢°ë„')\n",
    "plt.ylabel('ë¹ˆë„')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… ì°¨íŠ¸ ìƒì„± ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save-results"
   },
   "source": [
    "## ğŸ’¾ ê²°ê³¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save-to-excel"
   },
   "outputs": [],
   "source": [
    "# ê²°ê³¼ë¥¼ Excel íŒŒì¼ë¡œ ì €ì¥\n",
    "output_filename = f\"korean_sentiment_analysis_result_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
    "    # ì›ë³¸ ë°ì´í„°ì™€ ê²°ê³¼\n",
    "    combined_df = df.copy()\n",
    "    combined_df['ê°ì„±ë¶„ì„_ê²°ê³¼'] = results_df['sentiment']\n",
    "    combined_df['ì‹ ë¢°ë„'] = results_df['confidence']\n",
    "    combined_df.to_excel(writer, sheet_name='ê°ì„±ë¶„ì„_ê²°ê³¼', index=False)\n",
    "    \n",
    "    # ê°ì„±ë³„ í†µê³„\n",
    "    stats_df = pd.DataFrame({\n",
    "        'ê°ì„±': sentiment_counts.index,\n",
    "        'í…ìŠ¤íŠ¸_ìˆ˜': sentiment_counts.values,\n",
    "        'ë¹„ìœ¨(%)': [(count / len(results_df)) * 100 for count in sentiment_counts.values]\n",
    "    })\n",
    "    stats_df.to_excel(writer, sheet_name='ê°ì„±ë³„_í†µê³„', index=False)\n",
    "\n",
    "print(f\"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_filename}\")\n",
    "print(\"ğŸ“ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ë ¤ë©´ ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## ğŸ“¥ ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-file"
   },
   "outputs": [],
   "source": [
    "# ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
    "files.download(output_filename)\n",
    "print(\"âœ… íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## ğŸ‰ ì™„ë£Œ!\n",
    "\n",
    "í•œêµ­ì–´ í…ìŠ¤íŠ¸ ê°ì„±ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
    "\n",
    "### ğŸ“‹ ìˆ˜í–‰ëœ ì‘ì—…:\n",
    "1. âœ… í•œêµ­ì–´ ê°ì„±ë¶„ì„ ëª¨ë¸ ë¡œë“œ\n",
    "2. âœ… Excel íŒŒì¼ ì—…ë¡œë“œ ë° ì½ê¸°\n",
    "3. âœ… í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ìë™ ê°ì§€\n",
    "4. âœ… ê°ì„±ë¶„ì„ ì‹¤í–‰\n",
    "5. âœ… ê²°ê³¼ ì‹œê°í™”\n",
    "6. âœ… Excel íŒŒì¼ë¡œ ê²°ê³¼ ì €ì¥\n",
    "7. âœ… ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
    "\n",
    "### ğŸ’¡ ë‹¤ìŒì— ì‚¬ìš©í•  ë•Œ:\n",
    "- ì´ ë…¸íŠ¸ë¶ì„ ë³µì‚¬í•˜ì—¬ ìƒˆë¡œìš´ ë¶„ì„ì— ì‚¬ìš©\n",
    "- ë‹¤ë¥¸ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë¶„ì„ ê°€ëŠ¥\n",
    "- ëª¨ë¸ì€ í•œ ë²ˆë§Œ ë‹¤ìš´ë¡œë“œí•˜ë©´ ë¨"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "í•œêµ­ì–´ ê°ì„±ë¶„ì„",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

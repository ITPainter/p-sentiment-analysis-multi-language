{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# üá∞üá∑ Korean Sentiment Analysis\n\n",
        "Simple Korean sentiment analysis in Google Colab.\n\n",
        "## How to use:\n",
        "1. Upload Excel file with text column\n",
        "2. Run all cells\n",
        "3. Download results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "models-info"
      },
      "source": [
        "## ü§ñ Available Korean Models\n\n",
        "### Primary Model (Current):\n",
        "- **snunlp/KR-FinBert-SC** - Best performance for Korean sentiment\n\n",
        "### Alternative Models:\n",
        "- **beomi/KcELECTRA-base-v2022** - High accuracy alternative\n",
        "- **klue/roberta-base** - General purpose Korean model\n\n",
        "### Model Selection:\n",
        "You can change the `model_name` variable below to use different models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install"
      },
      "source": [
        "## üì¶ Install Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-packages"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install torch transformers pandas openpyxl matplotlib seaborn wordcloud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports"
      },
      "source": [
        "## üìö Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import-libs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from google.colab import files\n",
        "from io import BytesIO\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "print('‚úÖ Libraries loaded successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model"
      },
      "source": [
        "## ü§ñ Load Korean Sentiment Analysis Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load-model"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# üöÄ Korean Sentiment Analysis Models\n",
        "# =============================================================================\n",
        "\n",
        "# Primary model (best performance)\n",
        "model_name = 'snunlp/KR-FinBert-SC'\n",
        "\n",
        "# Alternative models (uncomment to use)\n",
        "# model_name = 'beomi/KcELECTRA-base-v2022'  # High accuracy alternative\n",
        "# model_name = 'klue/roberta-base'           # General purpose Korean model\n",
        "\n",
        "print(f\"üîÑ Loading model: {model_name}\")\n",
        "print(\"\\nüìã Model information:\")\n",
        "print(f\"   - Primary: snunlp/KR-FinBert-SC\")\n",
        "print(f\"   - Alternative: beomi/KcELECTRA-base-v2022\")\n",
        "print(f\"   - Fallback: klue/roberta-base\")\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"\\n‚úÖ Model loaded successfully on {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload"
      },
      "source": [
        "## üìÅ Upload Excel File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload-file"
      },
      "outputs": [],
      "source": [
        "# Upload Excel file\n",
        "print(\"üìÅ Please upload your Excel file (.xlsx)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the first uploaded file\n",
        "filename = list(uploaded.keys())[0]\n",
        "print(f\"‚úÖ File uploaded: {filename}\")\n",
        "\n",
        "# Read Excel file\n",
        "df = pd.read_excel(BytesIO(uploaded[filename]))\n",
        "print(f\"üìä Data loaded: {len(df)} rows, {len(df.columns)} columns\")\n",
        "print(\"\\nüìã Columns:\", list(df.columns))\n",
        "print(\"\\nüîç First few rows:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "select-column"
      },
      "source": [
        "## üìù Select Text Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "column-selection"
      },
      "outputs": [],
      "source": [
        "# Set text column name (modify this to match your column name)\n",
        "text_column = 'text'  # Change this to your actual column name\n",
        "\n",
        "# Common column names for Korean text\n",
        "# text_column = 'comment'    # ÎåìÍ∏Ä\n",
        "# text_column = 'review'     # Î¶¨Î∑∞\n",
        "# text_column = 'ÎåìÍ∏Ä'       # Korean column name\n",
        "# text_column = 'Î¶¨Î∑∞'       # Korean column name\n",
        "\n",
        "# Check if column exists\n",
        "if text_column not in df.columns:\n",
        "    print(f\"‚ùå Column '{text_column}' not found. Available columns: {list(df.columns)}\")\n",
        "    print(\"\\nüí° Please modify the 'text_column' variable above to match your column name\")\n",
        "    print(\"\\nüîç Common Korean column names: comment, review, ÎåìÍ∏Ä, Î¶¨Î∑∞, text\")\n",
        "else:\n",
        "    print(f\"‚úÖ Text column selected: {text_column}\")\n",
        "    print(f\"üìù Sample text: {df[text_column].iloc[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sentiment-analysis"
      },
      "source": [
        "## üß† Perform Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "analysis"
      },
      "outputs": [],
      "source": [
        "def analyze_sentiment(text):\n",
        "    \"\"\"Analyze sentiment of Korean text\"\"\"\n",
        "    try:\n",
        "        # Tokenize text\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128, padding=True)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "        \n",
        "        # Get prediction\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            probabilities = torch.softmax(outputs.logits, dim=1)\n",
        "            \n",
        "        # Get sentiment and confidence\n",
        "        sentiment_id = torch.argmax(probabilities, dim=1).item()\n",
        "        confidence = probabilities[0][sentiment_id].item()\n",
        "        \n",
        "        # Map sentiment ID to label (Korean models typically use 3 classes)\n",
        "        sentiment_labels = ['negative', 'neutral', 'positive']\n",
        "        sentiment = sentiment_labels[sentiment_id]\n",
        "        \n",
        "        return sentiment, confidence\n",
        "    except Exception as e:\n",
        "        return 'error', 0.0\n",
        "\n",
        "# Analyze each text\n",
        "print(\"üîÑ Analyzing sentiments...\")\n",
        "results = []\n",
        "\n",
        "for idx, text in enumerate(df[text_column]):\n",
        "    if pd.isna(text) or str(text).strip() == '':\n",
        "        sentiment, confidence = 'neutral', 0.0\n",
        "    else:\n",
        "        sentiment, confidence = analyze_sentiment(str(text))\n",
        "    \n",
        "    results.append({\n",
        "        'text': text,\n",
        "        'sentiment': sentiment,\n",
        "        'confidence': confidence\n",
        "    })\n",
        "    \n",
        "    # Show progress\n",
        "    if (idx + 1) % 10 == 0:\n",
        "        print(f\"Progress: {idx + 1}/{len(df)}\")\n",
        "\n",
        "print(\"‚úÖ Sentiment analysis completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "create-results"
      },
      "source": [
        "## üìä Create Results DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "results-df"
      },
      "outputs": [],
      "source": [
        "# Create results DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Add original data\n",
        "for col in df.columns:\n",
        "    if col != text_column:\n",
        "        results_df[col] = df[col]\n",
        "\n",
        "# Reorder columns\n",
        "cols = ['text', 'sentiment', 'confidence'] + [col for col in df.columns if col != text_column]\n",
        "results_df = results_df[cols]\n",
        "\n",
        "print(\"üìä Results DataFrame created\")\n",
        "print(f\"\\nüìà Sentiment distribution:\")\n",
        "print(results_df['sentiment'].value_counts())\n",
        "print(f\"\\nüîç Sample results:\")\n",
        "results_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualization"
      },
      "source": [
        "## üé® Create Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "charts"
      },
      "outputs": [],
      "source": [
        "# Create charts\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Pie chart\n",
        "sentiment_counts = results_df['sentiment'].value_counts()\n",
        "ax1.pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%')\n",
        "ax1.set_title('Sentiment Distribution', fontweight='bold')\n",
        "\n",
        "# Bar chart\n",
        "ax2.bar(sentiment_counts.index, sentiment_counts.values)\n",
        "ax2.set_title('Sentiment Counts', fontweight='bold')\n",
        "ax2.set_ylabel('Count')\n",
        "for i, v in enumerate(sentiment_counts.values):\n",
        "    ax2.text(i, v + 0.5, str(v), ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download"
      },
      "source": [
        "## üíæ Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save-results"
      },
      "outputs": [],
      "source": [
        "# Save results\n",
        "output_file = f'korean_sentiment_results_{pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")}.xlsx'\n",
        "results_df.to_excel(output_file, index=False)\n",
        "files.download(output_file)\n",
        "print(f\"‚úÖ Results saved to: {output_file}\")\n",
        "print(\"üì• File download started!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary"
      },
      "source": [
        "## üéâ Summary\n\n",
        "‚úÖ **Korean sentiment analysis completed successfully!**\n\n",
        "### Model Used:\n",
        "- **snunlp/KR-FinBert-SC** (Primary model)\n\n",
        "### Alternative Models Available:\n",
        "- **beomi/KcELECTRA-base-v2022** - High accuracy alternative\n",
        "- **klue/roberta-base** - General purpose Korean model\n\n",
        "### To Try Different Models:\n",
        "1. Go to the 'Load Model' cell above\n",
        "2. Comment out the current model_name\n",
        "3. Uncomment one of the alternative models\n",
        "4. Re-run the analysis\n\n",
        "### Results:\n",
        "- **Total texts analyzed**: Check the results above\n",
        "- **Sentiment distribution**: Check the results above\n",
        "- **Average confidence**: Check the results above\n\n",
        "---\n\n",
        "**üí° Tip**: Different models may give slightly different results. Try multiple models for best accuracy!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
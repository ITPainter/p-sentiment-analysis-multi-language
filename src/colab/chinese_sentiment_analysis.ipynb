{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# üá®üá≥ Chinese Sentiment Analysis\n\n",
        "Simple Chinese sentiment analysis in Google Colab.\n\n",
        "## How to use:\n",
        "1. Upload Excel file with text column\n",
        "2. Run all cells\n",
        "3. Download results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install"
      },
      "source": [
        "## üì¶ Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-packages"
      },
      "outputs": [],
      "source": [
        "!pip install torch transformers pandas openpyxl matplotlib seaborn wordcloud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports"
      },
      "source": [
        "## üìö Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import-libs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from google.colab import files\n",
        "from io import BytesIO\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "print('‚úÖ Libraries loaded')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model"
      },
      "source": [
        "## ü§ñ Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load-model"
      },
      "outputs": [],
      "source": [
        "# Load Chinese sentiment model\n",
        "model_name = 'IDEA-CCNL/Erlangshen-RoBERTa-110M-Sentiment'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(f'‚úÖ Model loaded on {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload"
      },
      "source": [
        "## üìÅ Upload File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload-file"
      },
      "outputs": [],
      "source": [
        "# Upload Excel file\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "df = pd.read_excel(BytesIO(uploaded[filename]))\n",
        "print(f'‚úÖ File loaded: {len(df)} rows')\n",
        "print('Columns:', list(df.columns))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "analyze"
      },
      "source": [
        "## üß† Analyze Sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sentiment-analysis"
      },
      "outputs": [],
      "source": [
        "# Set text column name (change this to match your file)\n",
        "text_column = 'text'\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=128)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = torch.softmax(outputs.logits, dim=1)\n",
        "        sentiment_id = torch.argmax(probs, dim=1).item()\n",
        "        confidence = probs[0][sentiment_id].item()\n",
        "        labels = ['negative', 'positive']\n",
        "        return labels[sentiment_id], confidence\n",
        "\n",
        "# Analyze all texts\n",
        "results = []\n",
        "for text in df[text_column]:\n",
        "    if pd.isna(text):\n",
        "        sentiment, conf = 'neutral', 0.0\n",
        "    else:\n",
        "        sentiment, conf = analyze_sentiment(str(text))\n",
        "    results.append({'text': text, 'sentiment': sentiment, 'confidence': conf})\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print('‚úÖ Analysis complete!')\n",
        "print('\\nSentiment distribution:')\n",
        "print(results_df['sentiment'].value_counts())\n",
        "results_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualize"
      },
      "source": [
        "## üé® Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create-charts"
      },
      "outputs": [],
      "source": [
        "# Create charts\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Pie chart\n",
        "sentiment_counts = results_df['sentiment'].value_counts()\n",
        "ax1.pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%')\n",
        "ax1.set_title('Sentiment Distribution')\n",
        "\n",
        "# Bar chart\n",
        "ax2.bar(sentiment_counts.index, sentiment_counts.values)\n",
        "ax2.set_title('Sentiment Counts')\n",
        "ax2.set_ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download"
      },
      "source": [
        "## üíæ Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save-results"
      },
      "outputs": [],
      "source": [
        "# Save results\n",
        "output_file = 'chinese_sentiment_results.xlsx'\n",
        "results_df.to_excel(output_file, index=False)\n",
        "files.download(output_file)\n",
        "print('‚úÖ Results downloaded!')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… íŒŒì¼ ê²½ë¡œ ì„¤ì • (PC í™˜ê²½)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒŒì¼ ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
file_path = os.path.join(current_dir, 'c_movie_review.xlsx')
save_path = os.path.join(current_dir, 'c_movie_review_result.xlsx')
#file_path = os.path.join(current_dir, 'k_movie_review.xlsx')
#save_path = os.path.join(current_dir, 'k_movie_review_result.xlsx')

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… í°íŠ¸ ì„¤ì • (Windows í™˜ê²½)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import matplotlib.font_manager as fm
import matplotlib.pyplot as plt

# Windows ê¸°ë³¸ í°íŠ¸ ì‚¬ìš© (í°íŠ¸ ê²½ê³  ì œê±°)
plt.rcParams['font.family'] = ['Malgun Gothic']
plt.rcParams['axes.unicode_minus'] = False

# í°íŠ¸ ê²½ë¡œ ì„¤ì • (Windows í™˜ê²½)
font_path_ko = 'C:/Windows/Fonts/malgun.ttf'  # ë§‘ì€ ê³ ë”•
font_path_zh = 'C:/Windows/Fonts/simsun.ttc'  # SimSun

# í°íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ì„¤ì •
if os.path.exists(font_path_ko):
    nanum_font = fm.FontProperties(fname=font_path_ko, size=16)
else:
    # ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
    nanum_font = fm.FontProperties(size=16)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… ê²½ê³  ë©”ì‹œì§€ ë„ê¸°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import warnings
warnings.filterwarnings("ignore", category=UserWarning)

# matplotlib í°íŠ¸ ê²½ê³  ì™„ì „ ì°¨ë‹¨
import logging
logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import re
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… í•œêµ­ì–´ ëª¨ë¸ (ì—…ë°ì´íŠ¸)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
model_name_ko = "snunlp/KR-FinBert-SC"  # ê°€ì¥ ì •í™•í•œ í•œêµ­ì–´ ê°ì •ë¶„ì„ ëª¨ë¸

# ğŸ† í•œêµ­ì–´ ê°ì •ë¶„ì„ ëª¨ë¸ ìˆœìœ„
# 1. snunlp/KR-FinBert-SC (ê¸ˆìœµ í…ìŠ¤íŠ¸, ì¼ë°˜ í…ìŠ¤íŠ¸ ëª¨ë‘ ìš°ìˆ˜)
# 2. beomi/KcELECTRA-base-v2022 (ìµœì‹  ì—…ë°ì´íŠ¸)
# 3. klue/roberta-base (KLUE í”„ë¡œì íŠ¸)
# 4. alsgyu/sentiment-analysis-fine-tuned-model (ì´ì „ ì‚¬ìš© ëª¨ë¸)
tokenizer_ko = AutoTokenizer.from_pretrained(model_name_ko)
model_ko = AutoModelForSequenceClassification.from_pretrained(model_name_ko)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… ì¤‘êµ­ì–´ ëª¨ë¸ (ê°ì„± ë¶„ì„ ì „ìš©)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
model_name_zh = "IDEA-CCNL/Erlangshen-RoBERTa-110M-Sentiment"

# ğŸ¥ ì¤‘êµ­ì–´ ì˜í™” ë¦¬ë·°ìš© ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ (ê°ì„± ë¶„ì„ ì „ìš©)
# - IDEA-CCNL/Erlangshen-RoBERTa-110M-Sentiment (ê°ì„± ë¶„ì„ ì „ìš©, ì¶”ì²œ)
# - hfl/chinese-roberta-wwm-ext (ê¸°ë³¸ ëª¨ë¸, ê°ì„± ë¶„ì„ ë¶€ì í•©)
# - IDEAL-Future/bert-base-chinese-finetuned-douban-movie (ì˜í™” ë¦¬ë·° ì „ìš©)

tokenizer_zh = AutoTokenizer.from_pretrained(model_name_zh)
model_zh = AutoModelForSequenceClassification.from_pretrained(model_name_zh)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_ko.to(device)
model_zh.to(device)

labels = ["negative", "neutral", "positive"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… ê°ì„± ë¶„ì„ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def analyze_sentiments(texts, tokenizer, model):
    results = []
    batch_size = 16

    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i+batch_size]
        inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors="pt", max_length=128).to(device)
        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits
            probs = torch.softmax(logits, dim=-1)
            confs, preds = torch.max(probs, dim=-1)

        for pred, conf in zip(preds.tolist(), confs.tolist()):
            # ë””ë²„ê¹…: ì‹¤ì œ ì˜ˆì¸¡ê°’ ì¶œë ¥ (ì²˜ìŒ 5ê°œë§Œ)
            if len(results) < 5:
                print(f"ì˜ˆì¸¡ê°’: {pred}, ì‹ ë¢°ë„: {conf:.3f}")
            
            # ëª¨ë“  ëª¨ë¸ì— ì‹ ë¢°ë„ ê¸°ë°˜ ì¤‘ë¦½ ë¶„ë¥˜ ì ìš©
            if conf < 0.8:  # ì‹ ë¢°ë„ ì„ê³„ê°’ì„ ë†’ì„ (0.6 â†’ 0.8)
                label = "neutral"
            elif model == model_zh:
                # ì¤‘êµ­ì–´ ëª¨ë¸ ë¼ë²¨ ë§¤í•‘
                if pred == 0:
                    label = "negative"
                elif pred == 1:
                    label = "positive"
                else:
                    label = "neutral"
            else:
                # í•œêµ­ì–´ ëª¨ë¸ ë¼ë²¨ ë§¤í•‘ (KR-FinBert-SCëŠ” 0:ë¶€ì •, 1:ê¸ì •)
                if pred == 0:
                    label = "negative"
                elif pred == 1:
                    # ê¸ì • ì˜ˆì¸¡ì´ì§€ë§Œ ì¼ì • ë¹„ìœ¨ì€ ì¤‘ë¦½ìœ¼ë¡œ ì¡°ì •
                    if conf < 0.95:  # ë§¤ìš° ë†’ì€ ì‹ ë¢°ë„ê°€ ì•„ë‹ˆë©´ ì¤‘ë¦½
                        label = "neutral"
                    else:
                        label = "positive"
                else:
                    label = "neutral"
                
            results.append({
                'label': label,
                'confidence': round(conf, 2)
            })

    return results

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… í†µí•© ì‹œê°í™” ìƒì„± í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def create_integrated_visualizations(all_comments, all_labels, sheet_stats, current_dir):
    """ì „ì²´ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ì‹œê°í™” ìƒì„±"""
    print("\nğŸ¨ í†µí•© ì‹œê°í™” ìƒì„± ì¤‘...")
    
    # 1. ì „ì²´ ì›Œë“œí´ë¼ìš°ë“œ
    all_text = ' '.join(all_comments)
    
    # í•œêµ­ì–´/ì¤‘êµ­ì–´ í˜¼í•© í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
    all_text = re.sub(r'[^ê°€-í£ä¸€-é¾¯a-zA-Z0-9\s]', '', all_text)
    
    if all_text.strip():
        # í•œêµ­ì–´ í°íŠ¸ ê²½ë¡œ í™•ì¸ ë° ì„¤ì •
        if os.path.exists(font_path_ko):
            wordcloud_font = font_path_ko
            print(f"âœ… í•œêµ­ì–´ í°íŠ¸ ì‚¬ìš©: {wordcloud_font}")
        else:
            wordcloud_font = None
            print("âš ï¸ í•œêµ­ì–´ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")
        
        wordcloud_params = {
            'width': 1600,
            'height': 800,
            'background_color': 'white',
            'max_words': 300,
            'min_font_size': 12,
            'relative_scaling': 0.5,
            'colormap': 'plasma',
            'collocations': False,
            'font_path': wordcloud_font  # í•œêµ­ì–´ í°íŠ¸ ëª…ì‹œì  ì„¤ì •
        }
        
        wordcloud = WordCloud(**wordcloud_params).generate(all_text)
        
        plt.figure(figsize=(20, 10))
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis('off')
        plt.title("ì „ì²´ ì˜í™” ë¦¬ë·° ì›Œë“œí´ë¼ìš°ë“œ", fontproperties=nanum_font, fontsize=20)
        
        wordcloud_path = os.path.join(current_dir, "ì „ì²´_ì›Œë“œí´ë¼ìš°ë“œ.png")
        plt.savefig(wordcloud_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ ì „ì²´ ì›Œë“œí´ë¼ìš°ë“œ ì €ì¥ë¨: ì „ì²´_ì›Œë“œí´ë¼ìš°ë“œ.png")
        plt.show()
    
    # 2. ì „ì²´ ê°ì„± ë¶„ì„ í†µê³„
    total_label_counts = pd.Series(all_labels).value_counts()
    total_count = len(all_labels)
    
    print(f"\nğŸ“Š ì „ì²´ ê°ì„± ë¶„ì„ í†µê³„ (ì´ {total_count}ê°œ ëŒ“ê¸€)")
    for label in ['positive', 'neutral', 'negative']:
        count = total_label_counts.get(label, 0)
        percent = (count / total_count) * 100 if total_count > 0 else 0
        print(f"- {label}: {count}ê°œ ({percent:.1f}%)")
    
    # 3. ì „ì²´ ë§‰ëŒ€ ê·¸ë˜í”„
    plt.figure(figsize=(12, 8))
    total_label_counts.reindex(['positive', 'neutral', 'negative'], fill_value=0).plot(
        kind='bar', color=['lightgreen', 'lightgray', 'lightcoral']
    )
    plt.title("ì „ì²´ ì˜í™” ë¦¬ë·° ê°ì„± ë¶„ì„ í†µê³„", fontproperties=nanum_font, fontsize=16)
    plt.ylabel("ëŒ“ê¸€ ìˆ˜", fontproperties=nanum_font)
    plt.xticks(rotation=0, fontproperties=nanum_font)
    
    bar_path = os.path.join(current_dir, "ì „ì²´_ë§‰ëŒ€ê·¸ë˜í”„.png")
    plt.savefig(bar_path, dpi=300, bbox_inches='tight')
    print(f"ğŸ’¾ ì „ì²´ ë§‰ëŒ€ ê·¸ë˜í”„ ì €ì¥ë¨: ì „ì²´_ë§‰ëŒ€ê·¸ë˜í”„.png")
    plt.show()
    
    # 4. ì „ì²´ ì›í˜• ì°¨íŠ¸
    plt.figure(figsize=(10, 8))
    plt.pie(total_label_counts, labels=total_label_counts.index, autopct='%1.1f%%', 
            colors=['lightgreen', 'lightgray', 'lightcoral'])
    plt.title("ì „ì²´ ì˜í™” ë¦¬ë·° ê°ì„± ë¶„ì„ ë¹„ìœ¨", fontproperties=nanum_font, fontsize=16)
    
    pie_path = os.path.join(current_dir, "ì „ì²´_ì›í˜•ì°¨íŠ¸.png")
    plt.savefig(pie_path, dpi=300, bbox_inches='tight')
    print(f"ğŸ’¾ ì „ì²´ ì›í˜• ì°¨íŠ¸ ì €ì¥ë¨: ì „ì²´_ì›í˜•ì°¨íŠ¸.png")
    plt.show()
    
    # 5. ì‹œíŠ¸ë³„ ë¹„êµ ì°¨íŠ¸
    if len(sheet_stats) > 1:
        sheet_names = list(sheet_stats.keys())
        positive_counts = [sheet_stats[name]['positive'] for name in sheet_names]
        neutral_counts = [sheet_stats[name]['neutral'] for name in sheet_names]
        negative_counts = [sheet_stats[name]['negative'] for name in sheet_names]
        
        x = np.arange(len(sheet_names))
        width = 0.25
        
        plt.figure(figsize=(15, 8))
        plt.bar(x - width, positive_counts, width, label='Positive', color='lightgreen')
        plt.bar(x, neutral_counts, width, label='Neutral', color='lightgray')
        plt.bar(x + width, negative_counts, width, label='Negative', color='lightcoral')
        
        plt.xlabel('ì˜í™”', fontproperties=nanum_font)
        plt.ylabel('ëŒ“ê¸€ ìˆ˜', fontproperties=nanum_font)
        plt.title('ì˜í™”ë³„ ê°ì„± ë¶„ì„ ë¹„êµ', fontproperties=nanum_font, fontsize=16)
        plt.xticks(x, sheet_names, fontproperties=nanum_font)
        plt.legend()
        plt.tight_layout()
        
        comparison_path = os.path.join(current_dir, "ì˜í™”ë³„_ë¹„êµì°¨íŠ¸.png")
        plt.savefig(comparison_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ ì˜í™”ë³„ ë¹„êµ ì°¨íŠ¸ ì €ì¥ë¨: ì˜í™”ë³„_ë¹„êµì°¨íŠ¸.png")
        plt.show()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… ì‹œíŠ¸ë³„ ì²˜ë¦¬ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def process_excel_sheets(file_path, save_path):
    # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
    current_dir = os.path.dirname(os.path.abspath(__file__))
    
    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(file_path):
        print(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        print("ğŸ“ í˜„ì¬ ë””ë ‰í† ë¦¬ì— 'movie_review.xlsx' íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    xlsx = pd.ExcelFile(file_path)
    sheet_names = xlsx.sheet_names
    print("ğŸ“„ í˜„ì¬ ì‹œíŠ¸ ëª©ë¡:", sheet_names)

    sheet_dict = {}
    
    # ì „ì²´ í†µê³„ë¥¼ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘
    all_comments = []
    all_labels = []
    all_confidences = []
    sheet_stats = {}

    for sheet in sheet_names:
        print(f"\nğŸ¬ ì²˜ë¦¬ ì¤‘ì¸ ì‹œíŠ¸: {sheet}")

        try:
            # Read the sheet and assume the header is on the first row (row 0)
            df = pd.read_excel(file_path, sheet_name=sheet, header=0)
            print(f"ğŸ“„ ì‹œíŠ¸ '{sheet}'ì˜ ì»¬ëŸ¼ ëª©ë¡:", df.columns.tolist()) # Add this line to print column names
        except Exception as e:
            print(f"âš ï¸ ì‹œíŠ¸ '{sheet}' ì½ê¸° ì‹¤íŒ¨: {e}")
            continue

        target_column = None
        # Check if any column name matches the target names (case-insensitive)
        for col in df.columns:
            if col.lower() in ['comment', 'ëŒ“ê¸€', 'review', 'text', 'comments']: # Added 'comments' to the list
                target_column = col
                break

        # If column name not found, try accessing by index (assuming 'D' is index 3)
        if target_column is None and len(df.columns) > 3:
             target_column = df.columns[3]
             print(f"âš ï¸ ëŒ“ê¸€ ì»¬ëŸ¼ ì´ë¦„ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ Dì—´ (ì¸ë±ìŠ¤ 3)ì˜ '{target_column}' ì»¬ëŸ¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")


        if target_column is None:
            print("âš ï¸ ëŒ“ê¸€ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'comment', 'ëŒ“ê¸€', 'review', 'text', 'comments' ì¤‘ í•˜ë‚˜ê°€ í•„ìš”í•˜ê±°ë‚˜ Dì—´ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue

        comments = df[target_column].dropna().tolist()

        if not comments:
            print("âš ï¸ ëŒ“ê¸€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        # ì‹œíŠ¸ ì´ë¦„ì—ì„œ ì–¸ì–´ êµ¬ë¶„ ë° í‘œì‹œìš© ì´ë¦„ ë¶„ë¦¬
        print(f"ğŸ” ì‹œíŠ¸ ì´ë¦„ í™•ì¸: '{sheet}'") # Debug print
        if sheet.lower().startswith("k"): # Changed to lower() for case-insensitivity
            tokenizer = tokenizer_ko
            model = model_ko
            lang_name = "í•œêµ­ì–´"
            display_name = sheet[1:] if len(sheet) > 1 else sheet
            colors_bar = ['skyblue', 'lightgray', 'blue']
            colors_pie = ['skyblue', 'lightgray', 'blue']
            wordcloud_font = font_path_ko if os.path.exists(font_path_ko) else None
            print("âœ… í•œêµ­ì–´ ì‹œíŠ¸ë¡œ íŒë‹¨ë¨") # Debug print
        elif sheet.lower().startswith("c"): # Changed to lower() for case-insensitivity
            tokenizer = tokenizer_zh
            model = model_zh
            lang_name = "ì¤‘êµ­ì–´"
            display_name = sheet[1:] if len(sheet) > 1 else sheet
            colors_bar = ['salmon', 'lightgray', 'red']
            colors_pie = ['salmon', 'lightgray', 'red']
            wordcloud_font = font_path_zh if os.path.exists(font_path_zh) else None
            print("âœ… ì¤‘êµ­ì–´ ì‹œíŠ¸ë¡œ íŒë‹¨ë¨") # Debug print
        else:
            print(f"âš ï¸ ì‹œíŠ¸ '{sheet}'ì˜ ì²« ê¸€ìë¡œ ì–¸ì–´ë¥¼ íŒë‹¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        print(f"ğŸŒ ì–¸ì–´ íŒë‹¨: {lang_name}")

        # ê°ì„± ë¶„ì„
        results = analyze_sentiments(comments, tokenizer, model)

        # ë¶„ì„ ê²°ê³¼ DataFrameì— ì¶”ê°€
        df = df.loc[df[target_column].notna()].copy()
        df["label"] = [r['label'] for r in results]
        df["confidence"] = [r['confidence'] for r in results]

        # ì‹œíŠ¸ë³„ í†µê³„ ìˆ˜ì§‘ (ì´ë¯¸ì§€ ìƒì„±í•˜ì§€ ì•ŠìŒ)
        label_counts = pd.Series([r['label'] for r in results]).value_counts()
        total = label_counts.sum()

        print(f"\nâœ… ì‹œíŠ¸ë³„ ê°ì„± ë¶„ì„ ìš”ì•½ (ì˜í™”: {display_name})")
        for label in ['positive', 'neutral', 'negative']:
            count = label_counts.get(label, 0)
            percent = (count / total) * 100 if total > 0 else 0
            print(f"- {label}: {count}ê°œ ({percent:.1f}%)")

        # ì „ì²´ í†µê³„ë¥¼ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘
        all_comments.extend(comments)
        all_labels.extend([r['label'] for r in results])
        all_confidences.extend([r['confidence'] for r in results])
        sheet_stats[display_name] = {
            'total': total,
            'positive': label_counts.get('positive', 0),
            'neutral': label_counts.get('neutral', 0),
            'negative': label_counts.get('negative', 0),
            'colors': colors_bar
        }

        # ì‹œíŠ¸ ê²°ê³¼ ì €ì¥ìš©
        sheet_dict[sheet] = df

    # ì „ì²´ ì‹œíŠ¸ ê²°ê³¼ë¥¼ ìƒˆ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥
    if sheet_dict:
        with pd.ExcelWriter(save_path, engine='openpyxl') as writer:
            for name, sheet_df in sheet_dict.items():
                sheet_df.to_excel(writer, sheet_name=name, index=False)
        print(f"\nâœ… ëª¨ë“  ì‹œíŠ¸ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {save_path}")
        
        # í†µí•© ì‹œê°í™” ìƒì„±
        if all_comments:
            create_integrated_visualizations(all_comments, all_labels, sheet_stats, current_dir)
    else:
        print("\nâš ï¸ ì²˜ë¦¬ëœ ì‹œíŠ¸ê°€ ì—†ì–´ ì €ì¥í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    print("ğŸš€ ê°ì„± ë¶„ì„ ì‹œì‘...")
    print(f"ğŸ“ ì…ë ¥ íŒŒì¼: {file_path}")
    print(f"ğŸ’¾ ì¶œë ¥ íŒŒì¼: {save_path}")
    
    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(file_path):
        print(f"\nâŒ ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        print("ğŸ“‹ ë‹¤ìŒ ì‚¬í•­ì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
        print("   1. 'movie_review.xlsx' íŒŒì¼ì´ í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸")
        print("   2. íŒŒì¼ëª…ì´ ì •í™•í•œì§€ í™•ì¸")
        print("   3. íŒŒì¼ì´ ì†ìƒë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸")
    else:
        process_excel_sheets(file_path, save_path)
        print("\nï¿½ï¿½ ê°ì„± ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")